/**
 * openaiService.ts - OpenAI æœåŠ¡
 * 
 * æ”¯æŒ OpenAI å®˜æ–¹ API åŠæ‰€æœ‰å…¼å®¹ OpenAI API æ ¼å¼çš„ç¬¬ä¸‰æ–¹æœåŠ¡
 * å¦‚ï¼šAzure OpenAIã€Moonshotã€DeepSeekã€é›¶ä¸€ä¸‡ç‰©ç­‰
 */

import { StudentResult, AppConfig } from '../types';
import { logAPIRequest, logAPIResponse, logAPIError, startTimer, endTimer } from './debug-utils';

// ==================== é»˜è®¤é…ç½® ====================

export const OPENAI_DEFAULTS = {
    endpoint: 'https://openrouter.ai/api/v1/chat/completions',
    models: ['google/gemini-2.5-flash', 'google/gemini-2.0-flash-001', 'openai/gpt-4o', 'openai/gpt-4o-mini', 'anthropic/claude-3.5-sonnet']
};

// ==================== ç±»å‹å®šä¹‰ ====================

export interface OpenAIConfig {
    apiKey: string;
    endpoint?: string;  // æ”¯æŒè‡ªå®šä¹‰ç¬¬ä¸‰æ–¹ API åœ°å€
    modelName?: string;
}

interface OpenAIMessage {
    role: 'system' | 'user' | 'assistant';
    content: string | OpenAIContentPart[];
}

type OpenAIContentPart =
    | { type: 'text'; text: string }
    | { type: 'image_url'; image_url: { url: string; detail?: 'low' | 'high' | 'auto' } };

interface OpenAIResponse {
    choices: Array<{
        message: {
            content: string;
        };
    }>;
}

interface OpenAIStreamChunk {
    choices: Array<{
        delta: {
            content?: string;
        };
    }>;
}

// ==================== æ ¸å¿ƒè°ƒç”¨å‡½æ•° ====================

/**
 * è°ƒç”¨ OpenAI å…¼å®¹ API
 * æ”¯æŒæ‰€æœ‰ OpenAI æ ¼å¼çš„ç¬¬ä¸‰æ–¹ API
 */
export async function callOpenAI(
    config: OpenAIConfig,
    systemPrompt: string,
    userPrompt: string,
    imageBase64?: string,
    options?: {
        jsonMode?: boolean;
        temperature?: number;
        maxTokens?: number;
    }
): Promise<string> {
    let endpoint = config.endpoint || OPENAI_DEFAULTS.endpoint;

    // è‡ªåŠ¨ä¿®æ­£ endpoint: å¦‚æœä»¥ /api ç»“å°¾ï¼Œå¾ˆå¯èƒ½æ˜¯ gptsapi.net è¿™ç§ä»£ç†åœ°å€ï¼Œéœ€è¦è¡¥å…¨
    if (endpoint.endsWith('/api')) {
        endpoint = endpoint + '/v1/chat/completions';
    } else if (endpoint.endsWith('/v1')) {
        endpoint = endpoint + '/chat/completions';
    }

    const modelName = config.modelName || 'gpt-4o';

    // æ„å»ºæ¶ˆæ¯
    const userContent: OpenAIContentPart[] = [{ type: 'text', text: userPrompt }];

    if (imageBase64) {
        // å¤„ç†å›¾ç‰‡æ ¼å¼ï¼šæ”¯æŒçº¯ base64 æˆ–å®Œæ•´ data URL
        const imageUrl = imageBase64.startsWith('data:')
            ? imageBase64  // å·²ç»æ˜¯å®Œæ•´çš„ data URLï¼Œç›´æ¥ä½¿ç”¨
            : `data:image/jpeg;base64,${imageBase64}`;  // çº¯ base64ï¼Œæ·»åŠ å‰ç¼€

        userContent.push({
            type: 'image_url',
            image_url: {
                url: imageUrl,
                detail: 'high'
            }
        });
    }

    const messages: OpenAIMessage[] = [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: userContent }
    ];

    const body: Record<string, unknown> = {
        model: modelName,
        messages,
        temperature: options?.temperature ?? 0.3
    };

    if (options?.maxTokens) {
        body.max_tokens = options.maxTokens;
    }

    if (options?.jsonMode) {
        body.response_format = { type: 'json_object' };
    }

    // æ„å»º headersï¼ŒOpenRouter éœ€è¦é¢å¤–çš„ HTTP-Referer å’Œ X-Title
    const headers: Record<string, string> = {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${config.apiKey}`
    };

    // æ£€æµ‹æ˜¯å¦ä¸º OpenRouter endpointï¼Œæ·»åŠ é¢å¤– headers
    if (endpoint.includes('openrouter.ai')) {
        headers['HTTP-Referer'] = 'https://ai-grading.app';
        headers['X-Title'] = 'AI Grading Assistant';
    }

    // ğŸ” è°ƒè¯•æ—¥å¿—
    logAPIRequest(endpoint, 'POST', { model: modelName, hasImage: !!imageBase64 });
    startTimer(`openai-${modelName}`);

    let response: Response;
    try {
        response = await fetch(endpoint, {
            method: 'POST',
            headers,
            body: JSON.stringify(body)
        });
    } catch (fetchError) {
        // ç½‘ç»œå±‚é”™è¯¯ (CORS, è¿æ¥å¤±è´¥ç­‰)
        endTimer(`openai-${modelName}`);
        logAPIError(endpoint, fetchError);
        throw new Error(`ç½‘ç»œè¯·æ±‚å¤±è´¥: ${(fetchError as Error).message}`);
    }

    const duration = endTimer(`openai-${modelName}`);
    logAPIResponse(endpoint, response.status, undefined, duration);

    if (!response.ok) {
        const errorBody = await response.json().catch(() => ({ message: response.statusText }));
        console.error('[OpenAI] Error body:', errorBody);
        const { parseAPIError } = await import('./ai-error');
        throw parseAPIError(response.status, errorBody);
    }


    const data: OpenAIResponse = await response.json();
    return data.choices?.[0]?.message?.content || '';
}

/**
 * æµå¼è°ƒç”¨ OpenAI å…¼å®¹ API
 * é€å—è¿”å›å†…å®¹ï¼Œå®ç°å®æ—¶æ˜¾ç¤ºæ•ˆæœ
 */
export async function* callOpenAIStream(
    config: OpenAIConfig,
    systemPrompt: string,
    userPrompt: string,
    imageBase64?: string,
    options?: {
        temperature?: number;
        maxTokens?: number;
    }
): AsyncGenerator<string, void, unknown> {
    let endpoint = config.endpoint || OPENAI_DEFAULTS.endpoint;

    // è‡ªåŠ¨ä¿®æ­£ endpoint
    if (endpoint.endsWith('/api')) {
        endpoint = endpoint + '/v1/chat/completions';
    } else if (endpoint.endsWith('/v1')) {
        endpoint = endpoint + '/chat/completions';
    }

    const modelName = config.modelName || 'gpt-4o';

    // æ„å»ºæ¶ˆæ¯
    const userContent: OpenAIContentPart[] = [{ type: 'text', text: userPrompt }];

    if (imageBase64) {
        // å¤„ç†å›¾ç‰‡æ ¼å¼ï¼šæ”¯æŒçº¯ base64 æˆ–å®Œæ•´ data URL
        const imageUrl = imageBase64.startsWith('data:')
            ? imageBase64
            : `data:image/jpeg;base64,${imageBase64}`;

        userContent.push({
            type: 'image_url',
            image_url: {
                url: imageUrl,
                detail: 'high'
            }
        });
    }

    const messages: OpenAIMessage[] = [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: userContent }
    ];

    const body: Record<string, unknown> = {
        model: modelName,
        messages,
        temperature: options?.temperature ?? 0.3,
        stream: true  // å¼€å¯æµå¼è¾“å‡º
    };

    if (options?.maxTokens) {
        body.max_tokens = options.maxTokens;
    }

    // OpenRouter headers
    const headers: Record<string, string> = {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${config.apiKey}`
    };
    if (endpoint.includes('openrouter.ai')) {
        headers['HTTP-Referer'] = 'https://ai-grading.app';
        headers['X-Title'] = 'AI Grading Assistant';
    }

    const response = await fetch(endpoint, {
        method: 'POST',
        headers,
        body: JSON.stringify(body)
    });

    if (!response.ok) {
        const errorBody = await response.json().catch(() => ({ message: response.statusText }));
        const { parseAPIError } = await import('./ai-error');
        throw parseAPIError(response.status, errorBody);
    }

    // å¤„ç†æµå¼å“åº”
    const reader = response.body?.getReader();
    if (!reader) {
        throw new Error('Response body is not readable');
    }

    const decoder = new TextDecoder();
    let buffer = '';

    try {
        while (true) {
            const { done, value } = await reader.read();
            if (done) break;

            buffer += decoder.decode(value, { stream: true });
            const lines = buffer.split('\n');
            buffer = lines.pop() || '';

            for (const line of lines) {
                const trimmed = line.trim();
                if (!trimmed || trimmed === 'data: [DONE]') continue;

                if (trimmed.startsWith('data: ')) {
                    try {
                        const json: OpenAIStreamChunk = JSON.parse(trimmed.slice(6));
                        const content = json.choices?.[0]?.delta?.content;
                        if (content) {
                            yield content;  // é€å—è¿”å›å†…å®¹
                        }
                    } catch (e) {
                        console.warn('[OpenAI Stream] Parse error:', e);
                    }
                }
            }
        }
    } finally {
        reader.releaseLock();
    }
}

/**
 * å¤šå›¾ç‰‡è°ƒç”¨ OpenAI å…¼å®¹ API
 */
export async function callOpenAIMultiImage(
    config: OpenAIConfig,
    systemPrompt: string,
    userPrompt: string,
    images: Array<{ base64: string; label?: string }>,
    options?: {
        jsonMode?: boolean;
        temperature?: number;
    }
): Promise<string> {
    let endpoint = config.endpoint || OPENAI_DEFAULTS.endpoint;

    // è‡ªåŠ¨ä¿®æ­£ endpoint: å¦‚æœä»¥ /api ç»“å°¾ï¼Œå¾ˆå¯èƒ½æ˜¯ gptsapi.net è¿™ç§ä»£ç†åœ°å€ï¼Œéœ€è¦è¡¥å…¨
    if (endpoint.endsWith('/api')) {
        endpoint = endpoint + '/v1/chat/completions';
    } else if (endpoint.endsWith('/v1')) {
        endpoint = endpoint + '/chat/completions';
    }

    const modelName = config.modelName || 'gpt-4o';

    // æ„å»ºåŒ…å«å¤šå›¾ç‰‡çš„å†…å®¹
    const userContent: OpenAIContentPart[] = [{ type: 'text', text: userPrompt }];

    for (const img of images) {
        if (img.label) {
            userContent.push({ type: 'text', text: img.label });
        }
        // å¤„ç†å›¾ç‰‡æ ¼å¼ï¼šæ”¯æŒçº¯ base64 æˆ–å®Œæ•´ data URL
        const imageUrl = img.base64.startsWith('data:')
            ? img.base64
            : `data:image/jpeg;base64,${img.base64}`;

        userContent.push({
            type: 'image_url',
            image_url: {
                url: imageUrl,
                detail: 'high'
            }
        });
    }

    const messages: OpenAIMessage[] = [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: userContent }
    ];

    const body: Record<string, unknown> = {
        model: modelName,
        messages,
        temperature: options?.temperature ?? 0.3
    };

    if (options?.jsonMode) {
        body.response_format = { type: 'json_object' };
    }

    // OpenRouter headers
    const headers: Record<string, string> = {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${config.apiKey}`
    };
    if (endpoint.includes('openrouter.ai')) {
        headers['HTTP-Referer'] = 'https://ai-grading.app';
        headers['X-Title'] = 'AI Grading Assistant';
    }

    const response = await fetch(endpoint, {
        method: 'POST',
        headers,
        body: JSON.stringify(body)
    });

    if (!response.ok) {
        const errorBody = await response.json().catch(() => ({ message: response.statusText }));
        const { parseAPIError } = await import('./ai-error');
        throw parseAPIError(response.status, errorBody);
    }


    const data: OpenAIResponse = await response.json();
    return data.choices?.[0]?.message?.content || '';
}

/**
 * æµ‹è¯• OpenAI API è¿æ¥
 */
export async function testOpenAIConnection(config: OpenAIConfig): Promise<boolean> {
    try {
        const endpoint = config.endpoint || OPENAI_DEFAULTS.endpoint;

        const response = await fetch(endpoint, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'Authorization': `Bearer ${config.apiKey}`
            },
            body: JSON.stringify({
                model: config.modelName || 'gpt-4o',
                messages: [{ role: 'user', content: 'ping' }],
                max_tokens: 5
            }),
            signal: AbortSignal.timeout(10000)
        });

        return response.ok;
    } catch (e) {
        console.error('[OpenAI] Connection test failed:', e);
        return false;
    }
}

// ==================== è¾…åŠ©å‡½æ•° ====================

/**
 * è§£æ OpenAI API é”™è¯¯
 */
function parseOpenAIError(status: number, errorText: string, modelName: string): string {
    switch (status) {
        case 401:
            return 'API Key æ— æ•ˆæˆ–å·²è¿‡æœŸ';
        case 403:
            return 'API Key æƒé™ä¸è¶³';
        case 404:
            return `æ¨¡å‹ "${modelName}" ä¸å­˜åœ¨æˆ–ä¸å¯ç”¨`;
        case 429:
            return 'API è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·ç¨åé‡è¯•';
        case 500:
        case 502:
        case 503:
            return 'OpenAI æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•';
        default:
            return `API è°ƒç”¨å¤±è´¥ (${status}): ${errorText.slice(0, 100)}`;
    }
}

/**
 * ä» AppConfig åˆ›å»º OpenAI é…ç½®
 */
export function createOpenAIConfig(appConfig: AppConfig): OpenAIConfig {
    return {
        apiKey: appConfig.apiKey,
        endpoint: appConfig.endpoint || OPENAI_DEFAULTS.endpoint,
        modelName: appConfig.modelName
    };
}
