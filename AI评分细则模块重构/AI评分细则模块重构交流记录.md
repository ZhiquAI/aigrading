# AI 评分系统架构设计

**Date**: February 6, 2026 at 10:01 AM
**Turns**: 15
**Source**: [Gemini Chat](https://gemini.google.com/app/acafaa3cfd8d829c)

---

## Turn 1

### 👤 User

不同的学科有不同的题型，不同的题型又有不同的评分规则。评分规则中有通用规则，也有特殊规则。这个问题怎么解决，是优化 AI Prompt还是采用结构化UI或者有更好的解决方案？

### 🤖 Assistant

这是一个非常经典且具有挑战性的业务场景。单纯靠“优化 Prompt”或“单纯的 UI”都无法完美解决，最好的方案是采用 **“结构化配置 + 动态 Prompt 构建 + 确定性后处理”** 的混合架构。
简单的说，你需要把“评分规则”变成一种**中间件（Schema）**，而不是直接写死在 Prompt 里。
我为你准备了一份详细的架构设计方案，详细阐述了如何针对不同学科、题型构建一个通用的 AI 评分系统。AI 智能评分系统架构设计方案2月5日 23:41

### 总结与建议
解决这个问题的关键在于**“控制权的分离”**：

1. **UI 负责结构化输入**：让老师用最自然的方式（选框、填空）定义复杂的规则。
2. **AI 负责语义理解（模糊部分）**：判断学生是否“理解了概念”，是否“提到了关键点”。
3. **代码负责算分逻辑（精确部分）**：处理权重加成、扣分上限、总分统计。
建议你先从**JSON Schema 的定义**入手。一旦定义好了描述题型和评分规则的数据结构，剩下的就是编写 Prompt 模板来“填空”了。

## Turn 2

### 👤 User

*[This turn includes uploaded images]*

![所上传图片的预览图](assets/img-001.png)

这是当前的UI架构设计，如何改进？

### 🤖 Assistant

这是一个非常棒的 UI 原型，它已经具备了“结构化配置”的雏形，特别是“得分点逻辑（任选 N 点）”的设计，非常符合我们在上一轮对话中提到的 **Schema 驱动** 的理念。
为了让这个 UI 真正能够支撑起**“多学科 x 复杂规则”**的混合架构，我基于我们之前的架构设计方案，为你提供一份详细的 **UI 改进分析与重构建议**。
我为你生成了一个新的文档，详细拆解了当前界面的优缺点以及 V2.0 版本的改进方案。UI 改进方案与交互逻辑重构2月6日 09:49

### 对 UI 改进的具体操作建议

1. **分离“展示文本”与“AI 判断逻辑”**：
  - 目前的列表里，`3-3 加强科技创新投入...` 是一段长文本。
  - **建议**：把这个输入框一分为二。
    - 左边是 **"标准答案展示"**（给学生看）。
    - 右边（或下方折叠区）是 **"AI 判分关键词/要点"**。因为有时候标准答案很长很官话，但只要学生答到“投钱”就算对，这时候你需要显式地告诉 AI 这一点。
2. **明确“分值”的层级**：
  - 目前的 UI 中，“最多计算 3 个得分点”和“每点分值 2 分”是**全局策略**。
  - 下方的列表项中的分值框应该设为 `placeholder="2"`（灰色默认值），表明默认继承全局。如果老师在这里输入了 `3`，则高亮显示，表示这是**特殊权重**。
3. **增加“AI 辅助修正”**：
  - 点击“生成评分细则”后，不要直接弹出一个填好的表单，而是可以展示一个**Diff 视图**或者**思维导图**，让老师勾选哪些点是关键得分点，然后再渲染成你现在的这个列表。
通过这些改动，你的 UI 就不再只是一个“录入表单”，而变成了一个**“评分逻辑编排器”**，完美契合后台的 AI 处理流程。

## Turn 3

### 👤 User

为了简化操作，让教师直接上传试题图片和参考答案生成评分细则，这个在UI上如何体现？

### 🤖 Assistant

这是一个非常棒的思路！将“手动配置”转变为“AI 生成 + 人工确认”，是提升用户体验的关键一步。这意味着你的 UI 应该采用 **“AI 优先 (AI-First)”** 的交互模式，而不是传统的表单录入模式。
为了实现“上传即生成”的流畅体验，我为你设计了一套全新的 **三阶段交互流程 (The 3-Stage Flow)**。AI 自动生成评分细则 UI 交互设计2月5日 23:50

### 核心设计理念总结

1. **隐藏复杂性**：初始界面只有简单的“上传”，不要展示复杂的规则配置表单。
2. **左图右表**：这是 AI 辅助工具的标准范式。左边是 Raw Data（图片），右边是 Structured Data（细则），中间通过**高亮联动**建立联系。
3. **AI 填空，人类批改**：默认假设 AI 已经做完了 90% 的工作，老师只需要改那剩下的 10%（比如修正分值、补充漏掉的点）。

## Turn 4

### 👤 User

问题是我当前的项目是chrome sidepanel，空间有限啊

### 🤖 Assistant

这是一个非常关键的约束条件！Chrome Side Panel（侧边栏）的宽度通常只有 **300px - 500px**，之前的“左右分屏”设计在这里完全行不通，会导致界面拥挤不堪。
针对侧边栏这种 **“窄屏、垂直流”** 的特性，我为你重新设计了一套 **“垂直堆叠 + 上下文内嵌”** 的交互方案。
核心思路是：**不要试图同时显示全图和全表，而是把“证据”切片化，内嵌到每个规则卡片里。**Chrome Side Panel 适配版 UI 交互设计2月5日 23:54

### 为什么这个方案适合 Chrome Side Panel？

1. **解决了宽度焦虑**：不需要左右对照，直接在卡片内部看到“AI 为什么这么分”。
2. **信息密度可控**：默认收起卡片，老师可以一眼看到总分结构（例如：是不是一共 3 个点，共 6 分？）。
3. **操作流畅**：所有的编辑都在拇指/鼠标的短移动范围内，符合 Side Panel 的操作习惯。
你可以直接用这套 **“卡片流 + 内嵌切片”** 的设计来开发你的前端组件。

## Turn 5

### 👤 User

问题是单学科单题型好处理，如果涉及到多学科多提醒，生成的评分细则如何管理？

### 🤖 Assistant

这是一个非常深刻的问题。当维度扩展到“多学科 x 多题型”时，如果每一个规则都是孤立的，系统很快就会变成一团乱麻。
解决这个问题的核心在于：**“标准化元数据” + “多态策略模式”**。
你需要建立一个 **“评分规则库 (Rubric Library)”** 的概念，而不仅仅是针对某一道题的临时规则。
我为你制定了一份 **《多学科多题型评分细则管理与架构方案》**，从数据结构底层到 UI 管理层提供了完整的解决方案。多学科评分细则管理方案2月6日 09:52

### 核心建议
针对你的 Chrome Side Panel 项目，不要试图做一个“万能编辑器”，而是做 **“不同模式的编辑器”**。

1. **定义三种模式**：在代码里写三个不同的 React 组件（`AccumulationEditor`, `StepEditor`, `RubricEditor`）。
2. **统一入口**：在“规则库”列表里，根据 `strategy_type` 字段决定渲染哪个组件。
3. **标签系统**：依赖 `Subject` 和 `Tag` 标签来做筛选，这比文件夹目录结构更适合侧边栏的扁平化操作。

## Turn 6

### 👤 User

请基于多学科评分细则管理方案帮我设计一套完成UI交互界面设计稿

### 🤖 Assistant

这是一个基于 React + Tailwind CSS 的完整交互原型，专门为 Chrome Side Panel（侧边栏）的窄屏环境设计。
它完美实现了你在《多学科评分细则管理方案》中提出的核心概念：

1. **规则库视图 (Library View)**：管理模版和实例。
2. **多态编辑器 (Polymorphic Editor)**：根据 `strategy_type` 自动切换界面（采点型 vs 步骤型 vs 量表型）。
3. **AI 智能推荐**：模拟了上传图片后 AI 自动匹配模版的流程。

### 交互设计亮点解析
这个原型虽然在同一套 UI 框架下，但通过多态设计（Polymorphism）实现了针对不同学科的深度定制：

1. **颜色编码引导 (Color Coding)**：
  - **蓝色 (Default)**：用于历史、简答题等“采点累加型”。界面强调关键词列表。
  - **青色 (Teal)**：用于数学、理科等“逻辑步骤型”。界面强调左侧的连接线（Timeline），暗示步骤的先后逻辑关系。
  - **橙色 (Orange)**：用于作文等“维度量表型”。界面使用可折叠的卡片（Accordion），避免在窄屏上显示巨大的表格。
2. **空间效率优化 (Side Panel Optimized)**：
  - **折叠式设计**：作文评分量表默认只显示维度名称和权重，点击才展开具体的等级描述，节省了宝贵的垂直空间。
  - **紧凑型输入框**：所有的 Input 都去除了多余的 Padding，使用 `text-sm` 或 `text-xs`，确保在一屏内能看到更多内容。
  - **Sticky Header**：无论滚动多长，保存按钮和返回按钮永远固定在顶部，方便操作。
3. **智能流模拟**：
  - 在规则库页面的搜索栏右侧，我放置了一个 **"✨" (Sparkles)** 按钮。点击它会模拟“AI 分析图片 -> 自动推荐数学模版”的交互流程（弹出 Toast 提示），这对应了方案中的“AI 智能推荐管理”。
你可以直接将这段代码运行在 React 环境中，预览在 Chrome Side Panel 尺寸下的真实效果。

## Turn 7

### 👤 User

那要上传试题图片和参考答案图片UI如何设计？

### 🤖 Assistant

这是一个非常关键的交互环节。在 Chrome Side Panel 这样狭窄的空间（通常宽 300-400px）里，上传界面必须做到**“既不拥挤，又直观”**。
最好的方案是采用 **“上下分区的卡片式上传”**，并配合 **“渐进式反馈”**（上传前是框，上传后变缩略图）。
我将在现有的代码基础上新增一个 `UploadView`，并将其串联到“新建规则”的流程中。
主要改动如下：

1. **新增 UploadView**：包含“试题”和“参考答案”两个独立的上传卡片。
2. **交互状态管理**：处理“空状态”、“已上传预览”、“AI 分析加载中”三种状态。
3. **流程串联**：在规则库点击 `+` 或 `✨` -> 进入上传页 -> AI 生成 -> 进入编辑器。
4. **编辑器增强**：在编辑器顶部增加“原图”查看入口，形成闭环。

## Turn 8

### 👤 User

如果上传的试题图片和参考答案后经过AI生成的评分准则和实际有出入，如何处理？

### 🤖 Assistant

这是一个非常实际且必须解决的问题。AI 生成的结果很难达到 100% 准确，因此 **“人工修正 (Human-in-the-loop)”** 的体验至关重要。
在 Chrome Side Panel 这种窄屏环境下，处理“AI 偏差”的核心交互策略是：**上下文对照 (Context)** + **快速增删改 (CRUD)** + **策略重置 (Reset Strategy)**。
我对代码进行了以下关键升级来解决这个问题：

1. **新增“原图对照”浮层**：在编辑器中点击“查看原图”，会弹出一个半透明浮层显示原始图片，方便用户一边看图一边改文字。
2. **激活“策略切换”**：如果 AI 把“历史题”误判为“数学步骤题”，用户现在可以手动切换下拉菜单，系统会重置数据结构。
3. **完整的增删改能力**：实现了添加新得分点、删除错误得分点、修改分值和内容的完整状态逻辑，让用户能修补 AI 的遗漏。

## Turn 9

### 👤 User

新生成的评分细则如何管理？

### 🤖 Assistant

这是一个非常好的问题。新生成的评分细则如果不进行有效管理，很快就会变得杂乱无章。
基于我们当前的架构，我为你增加了一套完整的 **“生命周期管理”** 机制。现在，新生成的规则不仅仅是一个临时的草稿，而是可以被**保存、归档、标记**，并转化为**通用模版**的资产。
我在 `GradingSidePanel.tsx` 中进行了以下核心升级：

1. **状态持久化 (State Management)**：将静态的 `MOCK_LIBRARY` 升级为动态的 `library` 状态，实现了规则的**新增**和**更新**逻辑。
2. **模版转化 (Template Conversion)**：在编辑器顶部增加了 **“设为通用模版”** 开关。
  - *场景*：AI 生成了一个非常完美的“几何证明题”规则，你可以把它存为模版，以后所有几何题都用这个。
3. **标签管理 (Tagging System)**：增加了标签编辑功能，方便后续在规则库中筛选（如标记为“期末考”、“难点”）。
4. **保存反馈**：点击保存后会更新规则库，并自动返回列表页，让你看到新管理的规则。

## Turn 10

### 👤 User

同一学科不同题型如何处理？

### 🤖 Assistant

这是一个非常好的问题。在实际教学中，同一学科（例如数学）既有**计算题**（需要按步骤给分），又有**填空题**（只看结果关键词），甚至还有**探究题**（可能需要维度评分）。
处理这个问题的核心在于：**建立“学科题型”到“评分策略”的映射关系**。
我在代码中做了一个关键升级，引入了 `SUBJECT_CONFIG` 配置表。这不仅解决了 UI 上的联动选择问题，更重要的是它定义了：**“当我们选择数学填空题时，系统底层应该自动使用‘采点累加’策略；而选择数学证明题时，自动切换为‘逻辑步骤’策略。”**

### 主要变更点：

1. **配置驱动 (Config-Driven)**：新增 `SUBJECT_CONFIG` 常量，定义了学科、题型、策略的三级映射。
2. **二级筛选 (Sub-filter)**：在规则库中，选中“数学”后，会自动出现“计算题”、“证明题”、“填空题”的二级筛选 Tab。
3. **智能上传联动**：在新建规则页面，选择学科后，题型下拉框会自动更新。AI 生成时会根据你选的题型，自动采用正确的评分数据结构。

## Turn 11

### 👤 User

在同一学科教师要自定义添加题型AI如何处理？

### 🤖 Assistant

这是一个非常实际的高级需求。当教师需要添加一个系统预设中不存在的题型（例如数学学科中新增一个“**探究实验题**”）时，AI 无法凭空猜出这个新题型应该用什么规则（是按步骤给分？还是按维度打分？）。
解决方案的核心是：**“自定义映射 (Custom Mapping)”**。
即：允许用户输入自定义名称，但必须**强制用户指定底层的“评分策略”**。这样，AI 就知道了：“虽然我不知道什么是‘探究实验题’，但用户告诉我它通过‘维度量表’评分，那我就生成量表结构。”
我在代码中进行了以下升级：

1. **UI 升级**：在“选择题型”下拉框中增加了 `+ 自定义题型...` 选项。
2. **动态交互**：选中自定义后，会展开一个配置区，要求教师输入**题型名称**并选择**底层策略**（采点/步骤/量表）。
3. **生成逻辑适配**：AI 生成函数现在会读取用户的自定义策略，生成对应的数据结构。

## Turn 12

### 👤 User

当前生成的评分细则库要在云端同步，如何设计？

### 🤖 Assistant

这是一个非常棒的进阶需求。要实现评分细则的云端同步，我们需要引入后端数据库（Firestore）并配合身份验证（Auth）来实现“用户隔离”的数据存储。

### 架构设计思路

1. **数据模型 (Data Model)**：
  - 采用 **Firestore** 作为云端数据库。
  - 路径设计遵循用户隔离原则：`/artifacts/{appId}/users/{userId}/rules/{ruleId}`。
  - 每个评分细则（Rule）作为一个独立的 Document 存储。
2. **同步策略 (Sync Strategy)**：
  - **读 (Read)**：使用 `onSnapshot` 实时监听数据库。一旦云端数据变化（例如你在另一个设备上修改了规则），本地列表会自动更新。
  - **写 (Write)**：点击“保存”时，不再只是更新本地数组，而是调用 `setDoc` 将数据写入云端。
  - **初始化 (Onboarding)**：如果用户是第一次登录且云端没有任何数据，我们会自动将 `INITIAL_LIBRARY`（预设模版）写入云端，确保用户有初始数据可用。
3. **状态反馈 (UI Feedback)**：
  - 在界面顶部增加一个 **云端状态指示器**（云朵图标），显示“同步中”、“已同步”或“离线”。

---

### 代码实现
我已更新 `GradingSidePanel.tsx`，集成了 Firebase SDK，并实现了完整的同步逻辑。

## Turn 13

### 👤 User

评分细则模块只是当前项目的第一个模块，当设计好评分细则后进入到智能阅卷模块，因为是辅助智学网和好分数等平台（主要是通过操作智学网上答题卡图片利用AI技术实现智能阅卷）。智能阅卷模块包括辅助阅卷模式和自动阅卷模式。辅助模式下AI只打分不提交，教师手动提交；自动模式下AI自动打分自动提交，循环往复。基于上述描述，请为我设计UI交互页面。

### 🤖 Assistant

这是一个非常关键的业务流程闭环。从“规则制定”到“执行阅卷”，体验必须无缝衔接。
针对你描述的 **Chrome Side Panel (侧边栏) + 外部平台 (智学网/好分数) 挂件** 的场景，我为你设计了 **“智能阅卷控制台 (Intelligent Grading Console)”**。

### 核心设计理念

1. **非侵入式 HUD (Heads-Up Display)**：侧边栏是控制中心，不遮挡浏览器主区域的答题卡。
2. **模式切换 (Dual Mode)**：
  - **辅助模式 (Co-Pilot)**：侧重于“证据展示”和“快速修改”。AI 给出建议分，老师一键采纳或修正。
  - **自动模式 (Auto-Pilot)**：侧重于“安全监控”和“异常打断”。AI 连续工作，只在置信度低时暂停请求人工介入。
3. **视觉反馈**：通过颜色（绿/黄/红）明确告知用户当前 AI 的状态（扫描中、分析中、等待确认）。
我为你创建了一个新的组件文件 `IntelligentGrading.tsx`，它模拟了从规则库进入阅卷后的完整交互。Intelligent Grading Module2月6日 00:43

### 设计细节与交互逻辑说明

1. **模式差异化体验**：
  - **辅助模式**：界面核心是 `GradingCard`（评分卡片）。老师可以点击具体的得分点（Checkpoints）来切换 `met` 状态（即勾选/取消勾选），分数会实时联动计算。底部的按钮是“填分并提交”，模拟了老师在智学网上原本的手动操作，但只需要点一次。
  - **自动模式**：界面核心变成了 `AutoMonitor`（监控器）。大大的紫色倒计时圆环，让老师知道 AI 正在工作。下方的评分卡片变成了“只读/预览”状态，快速闪过。
2. **安全机制 (Safety Guardrails)**：
  - **置信度中断**：在代码逻辑中，我模拟了 `confidence < 0.8` 的情况。当 AI 拿不准时，自动模式会变红并暂停（Status: `paused`），强行要求老师介入。这是 AI 阅卷产品必须具备的“刹车”功能。
  - **倒计时确认**：在自动模式下，AI 分析完不会立刻提交，而是有一个 3秒的 `Countdown`。这给了老师一个“后悔窗口”，如果发现不对，可以立刻点击暂停。
3. **平台联动模拟**：
  - Header 部分加了一个小绿点 `已连接智学网阅卷页`，增强用户对“当前在操作哪个页面”的感知。
  - 状态文案明确写着 `正在写入智学网...`，让用户明白 Side Panel 正在通过 DOM 操作去控制主浏览器窗口。
4. **快捷操作**：
  - **AI 评语建议**：点击底部的标签可以直接把评语填入（虽然这个 Mock 里没做实际填入逻辑，但 UI 上体现了便捷性）。
  - **重评**：如果觉得 AI 这次彻底“发疯”了，可以点击重评重新触发 OCR 和分析。
这个界面设计既满足了“高效刷题”的需求（自动模式），又保留了“严谨负责”的底线（辅助模式+人工介入），非常适合 K12 教育场景。

## Turn 14

### 👤 User

_No content_

### 🤖 Assistant

很抱歉，之前的代码中存在一个语法错误，导致编译失败。
这主要是因为在 JSX 中直接使用大于号 `>` 时被解析器误判了。我正在修复这个问题，马上就好。
代码已修复，现在应该可以正常预览“智能阅卷控制台”的界面了。这个界面包含两种模式：

1. **辅助阅卷**：适合需要人工确认的场景，支持点击修改分数。
2. **自动阅卷**：适合大批量处理，带有置信度监控和自动提交倒计时。

## Turn 15

### 👤 User

_No content_

### 🤖 Assistant

非常抱歉，代码中遗漏了 `Loader2` 和 `Sparkles` 图标组件的引用，导致了运行错误。我已修复了这个问题，并检查了代码中所有使用的图标组件确保它们都已正确导入。
我已更新了代码文件，请直接查看。

---

*Exported from [Gemini Voyager](https://github.com/Nagi-ovo/gemini-voyager)*  
*Generated on February 6, 2026 at 10:01 AM*